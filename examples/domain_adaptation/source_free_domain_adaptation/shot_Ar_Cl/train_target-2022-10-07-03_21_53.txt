Namespace(root='/data/office-home/', data='OfficeHome', domain=['Cl'], val_ratio=0.0, train_resizing='ran.crop', val_resizing='default', resize_size=224, scale=[0.08, 1.0], ratio=[0.75, 1.3333333333333333], no_hflip=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), arch='resnet50', bottleneck_dim=256, no_pool=False, wn=False, scratch=False, load='./shot_Ar/checkpoints/best.pth', batch_size=64, lr=0.01, lr_gamma=10, lr_decay=0.75, momentum=0.9, weight_decay=0.001, epsilon=1e-05, lb_smooth=0.1, trade_off=0.0, workers=8, epochs=15, print_freq=10, seed=None, per_class_eval=False, log='./shot_Ar_Cl/', phase='train_target')
train_transform:  Compose(
    Compose(
    ResizeImage(size=(256, 256))
    RandomCrop(size=(224, 224), padding=None)
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
val_transform:  Compose(
    Compose(
    ResizeImage(size=(256, 256))
    CenterCrop(size=(224, 224))
)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
=> using model 'resnet50'
/home/guoxingzhuo/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:252: UserWarning: Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and will be removed in 0.15. Please access them via the appropriate Weights Enum instead.
  warnings.warn(
3.018354892730713 0.0628361701965332
Epoch: [0][ 0/69]	Time  2.13 ( 2.13)	Data  0.97 ( 0.97)	Loss   3.08 (  3.08)
2.9449563026428223 0.06175041198730469
2.759377956390381 0.09143447875976562
2.6782634258270264 0.09138679504394531
2.899219036102295 0.08489131927490234
2.6893415451049805 0.08656740188598633
2.6645803451538086 0.10201597213745117
2.742471218109131 0.09784078598022461
2.676980495452881 0.11976051330566406
2.475442886352539 0.15288162231445312
2.4577178955078125 0.1433124542236328
Epoch: [0][10/69]	Time  0.24 ( 0.41)	Data  0.09 ( 0.17)	Loss   2.60 (  2.83)
2.3890700340270996 0.1503448486328125
2.150564670562744 0.23314476013183594
2.425936222076416 0.15696144104003906
2.2218217849731445 0.1744401454925537
2.275895595550537 0.14758634567260742
2.250446081161499 0.1670064926147461
2.1225738525390625 0.17671918869018555
2.2422447204589844 0.18691802024841309
2.294070243835449 0.13188886642456055
2.094743251800537 0.19719147682189941
Epoch: [0][20/69]	Time  0.25 ( 0.33)	Data  0.09 ( 0.13)	Loss   2.29 (  2.63)
2.107597827911377 0.2180929183959961
2.348240375518799 0.1593780517578125
2.0451278686523438 0.21639060974121094
1.9339330196380615 0.22346115112304688
2.0127344131469727 0.19879579544067383
2.012843370437622 0.1995546817779541
2.058560371398926 0.20790719985961914
2.1062464714050293 0.2187340259552002
2.0448453426361084 0.2632880210876465
2.0626683235168457 0.19826745986938477
Epoch: [0][30/69]	Time  0.25 ( 0.30)	Data  0.09 ( 0.12)	Loss   2.26 (  2.52)
2.032254934310913 0.194685697555542
2.045283317565918 0.17372989654541016
1.9513769149780273 0.26398563385009766
1.9305124282836914 0.26397705078125
1.8194425106048584 0.2912735939025879
1.8199388980865479 0.2747197151184082
1.941183090209961 0.22679758071899414
1.7355220317840576 0.3084893226623535
1.8253737688064575 0.30234622955322266
1.7484898567199707 0.2844574451446533
Epoch: [0][40/69]	Time  0.25 ( 0.29)	Data  0.09 ( 0.11)	Loss   2.03 (  2.43)
1.7467052936553955 0.25192975997924805
1.9074500799179077 0.2686905860900879
1.7095210552215576 0.32740163803100586
1.8737726211547852 0.23297524452209473
1.7693657875061035 0.3092360496520996
1.65358567237854 0.2873067855834961
1.7697455883026123 0.2120504379272461
1.7686195373535156 0.2758316993713379
1.7619249820709229 0.2501850128173828
1.6483590602874756 0.3216836452484131
Epoch: [0][50/69]	Time  0.25 ( 0.28)	Data  0.09 ( 0.11)	Loss   1.97 (  2.35)
1.4698110818862915 0.31841063499450684
1.7281560897827148 0.2877011299133301
1.6464343070983887 0.2694110870361328
1.6110610961914062 0.3083992004394531
1.7756037712097168 0.27558469772338867
1.5487656593322754 0.33105015754699707
1.7214699983596802 0.28078365325927734
1.7202588319778442 0.3162527084350586
1.7056931257247925 0.2705075740814209
1.5603312253952026 0.31627368927001953
Epoch: [0][60/69]	Time  0.25 ( 0.28)	Data  0.09 ( 0.11)	Loss   1.88 (  2.28)
1.6828508377075195 0.26900672912597656
1.72832453250885 0.24384832382202148
1.6770751476287842 0.27204465866088867
1.5885812044143677 0.3264501094818115
1.4745452404022217 0.345644474029541
1.5744893550872803 0.34429049491882324
1.6980916261672974 0.3016023635864258
1.4969596862792969 0.8773379325866699
Test: [ 0/69]	Time  0.950 ( 0.950)	Loss 3.2748e+00 (3.2748e+00)	Acc@1  26.56 ( 26.56)
Test: [10/69]	Time  0.082 ( 0.162)	Loss 1.2639e+00 (2.3085e+00)	Acc@1  75.00 ( 50.00)
Test: [20/69]	Time  0.080 ( 0.124)	Loss 4.7115e-01 (2.5882e+00)	Acc@1  89.06 ( 43.08)
Test: [30/69]	Time  0.081 ( 0.111)	Loss 1.8931e+00 (2.6133e+00)	Acc@1  62.50 ( 43.55)
Test: [40/69]	Time  0.083 ( 0.105)	Loss 1.7490e+00 (2.5210e+00)	Acc@1  62.50 ( 45.16)
Test: [50/69]	Time  0.082 ( 0.101)	Loss 1.5206e+00 (2.4920e+00)	Acc@1  65.62 ( 46.08)
Test: [60/69]	Time  0.081 ( 0.098)	Loss 2.7432e+00 (2.4176e+00)	Acc@1  34.38 ( 47.69)
 * Acc@1 47.308
1.3415462970733643 0.3606715202331543
Epoch: [1][ 0/69]	Time  1.03 ( 1.03)	Data  0.87 ( 0.87)	Loss   1.70 (  1.70)
1.4762095212936401 0.3207972049713135
1.3007988929748535 0.33828020095825195
1.461661458015442 0.2676358222961426
1.356665849685669 0.34510159492492676
1.4688178300857544 0.30887269973754883
1.4056086540222168 0.3767399787902832
1.5652656555175781 0.28519773483276367
1.667555809020996 0.2809107303619385
1.4483120441436768 0.33202147483825684
1.5469775199890137 0.34562230110168457
Epoch: [1][10/69]	Time  0.25 ( 0.32)	Data  0.09 ( 0.16)	Loss   1.89 (  1.78)
1.6321794986724854 0.25623178482055664
1.4017412662506104 0.27870941162109375
1.4761443138122559 0.4002070426940918
1.495612621307373 0.3074312210083008
1.5976736545562744 0.3490011692047119
1.4504010677337646 0.3136014938354492
1.435297966003418 0.317594051361084
1.3237954378128052 0.3944587707519531
1.1552798748016357 0.37990546226501465
1.362816333770752 0.3513369560241699
Epoch: [1][20/69]	Time  0.25 ( 0.28)	Data  0.09 ( 0.13)	Loss   1.71 (  1.78)
1.4308922290802002 0.3426392078399658
1.4073271751403809 0.31335973739624023
1.383316159248352 0.3576643466949463
1.470017433166504 0.3742103576660156
1.3594369888305664 0.3906683921813965
1.3374743461608887 0.3493220806121826
1.363904356956482 0.3667604923248291
1.250739574432373 0.38742637634277344
1.1636486053466797 0.37551021575927734
1.214865803718567 0.3687472343444824
Epoch: [1][30/69]	Time  0.25 ( 0.27)	Data  0.09 ( 0.12)	Loss   1.58 (  1.75)
1.4236576557159424 0.3457627296447754
1.2984001636505127 0.3865938186645508
1.4387898445129395 0.3475947380065918
1.3749186992645264 0.35962677001953125
1.343544602394104 0.34595251083374023
1.4146931171417236 0.27649927139282227
1.641094446182251 0.29898858070373535
1.2924575805664062 0.3857290744781494
1.2074613571166992 0.39926958084106445
1.3848621845245361 0.3194427490234375
Epoch: [1][40/69]	Time  0.25 ( 0.27)	Data  0.10 ( 0.11)	Loss   1.70 (  1.75)
1.1736106872558594 0.3783383369445801
1.4277055263519287 0.32566261291503906
1.344812273979187 0.34322643280029297
1.2471694946289062 0.3539259433746338
1.1282716989517212 0.3704087734222412
1.098044753074646 0.4346733093261719
1.2301971912384033 0.42258262634277344
1.0507056713104248 0.3670990467071533
1.3414307832717896 0.3449869155883789
1.1090545654296875 0.42051076889038086
Epoch: [1][50/69]	Time  0.25 ( 0.26)	Data  0.09 ( 0.11)	Loss   1.53 (  1.72)
1.0952619314193726 0.49508237838745117
1.3780953884124756 0.3324573040008545
1.1299397945404053 0.4394664764404297
1.1601028442382812 0.39221763610839844
1.1135098934173584 0.36231327056884766
1.262070894241333 0.3481254577636719
1.1359820365905762 0.4020817279815674
1.1275848150253296 0.37868738174438477
1.0985996723175049 0.331540584564209
1.1035559177398682 0.39312171936035156
Epoch: [1][60/69]	Time  0.25 ( 0.26)	Data  0.09 ( 0.11)	Loss   1.50 (  1.69)
1.3205499649047852 0.3503904342651367
1.222015380859375 0.41901159286499023
1.281775951385498 0.42478108406066895
1.2299935817718506 0.34211063385009766
1.1304295063018799 0.40645384788513184
1.1826224327087402 0.37401390075683594
1.3778036832809448 0.3702540397644043
1.2326170206069946 0.9034836292266846
Test: [ 0/69]	Time  1.008 ( 1.008)	Loss 3.9895e+00 (3.9895e+00)	Acc@1  25.00 ( 25.00)
Test: [10/69]	Time  0.083 ( 0.169)	Loss 1.3637e+00 (2.4490e+00)	Acc@1  76.56 ( 49.57)
Test: [20/69]	Time  0.085 ( 0.128)	Loss 5.5671e-01 (2.6731e+00)	Acc@1  89.06 ( 45.24)
Test: [30/69]	Time  0.099 ( 0.116)	Loss 2.0758e+00 (2.7673e+00)	Acc@1  56.25 ( 44.71)
Test: [40/69]	Time  0.083 ( 0.109)	Loss 1.6888e+00 (2.6766e+00)	Acc@1  67.19 ( 46.27)
Test: [50/69]	Time  0.083 ( 0.104)	Loss 1.8191e+00 (2.6828e+00)	Acc@1  65.62 ( 47.30)
Test: [60/69]	Time  0.084 ( 0.101)	Loss 2.7731e+00 (2.5714e+00)	Acc@1  37.50 ( 49.31)
 * Acc@1 48.889
Traceback (most recent call last):
  File "/workspace/guoxingzhuo/Transfer-Learning-Library/examples/domain_adaptation/source_free_domain_adaptation/shot.py", line 354, in <module>
    main(args)
  File "/workspace/guoxingzhuo/Transfer-Learning-Library/examples/domain_adaptation/source_free_domain_adaptation/shot.py", line 126, in main
    train_target(train_loader, classifier, optimizer, lr_scheduler, epoch, args)
  File "/workspace/guoxingzhuo/Transfer-Learning-Library/examples/domain_adaptation/source_free_domain_adaptation/shot.py", line 243, in train_target
    pesudo_labels = collect_pseudo_labels(train_loader, model, args)
  File "/workspace/guoxingzhuo/Transfer-Learning-Library/examples/domain_adaptation/source_free_domain_adaptation/shot.py", line 156, in collect_pseudo_labels
    feature_list.append(f.detach().cpu())
KeyboardInterrupt
