Namespace(root='/data/office-home/', data='OfficeHome', domain=['Cl'], val_ratio=0.0, train_resizing='ran.crop', val_resizing='default', resize_size=224, scale=[0.08, 1.0], ratio=[0.75, 1.3333333333333333], no_hflip=False, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225), arch='resnet50', bottleneck_dim=256, no_pool=False, wn=False, scratch=False, load='./shot_Ar/checkpoints/best.pth', batch_size=64, lr=0.01, lr_gamma=10, lr_decay=0.75, momentum=0.9, weight_decay=0.001, epsilon=1e-05, lb_smooth=0.1, trade_off=0.0, workers=8, epochs=15, print_freq=10, seed=None, per_class_eval=False, log='./shot_Ar_Cl/', phase='train_target')
train_transform:  Compose(
    Compose(
    ResizeImage(size=(256, 256))
    RandomCrop(size=(224, 224), padding=None)
)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
val_transform:  Compose(
    Compose(
    ResizeImage(size=(256, 256))
    CenterCrop(size=(224, 224))
)
    ToTensor()
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
)
=> using model 'resnet50'
/home/guoxingzhuo/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:252: UserWarning: Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and will be removed in 0.15. Please access them via the appropriate Weights Enum instead.
  warnings.warn(
10 15 69
lr: 0.01
2.8206284046173096 0.0773458480834961
Epoch: [0][ 0/69]	Time  2.09 ( 2.09)	Data  0.98 ( 0.98)	Loss   2.90 (  2.90)
2.754973888397217 0.07322549819946289
2.894589424133301 0.07313394546508789
2.913785457611084 0.06206321716308594
2.905871868133545 0.06853628158569336
2.9001247882843018 0.05472898483276367
2.691202402114868 0.08769941329956055
2.5333433151245117 0.1306319236755371
2.5979456901550293 0.13190603256225586
2.642615795135498 0.12407493591308594
2.3739254474639893 0.12159156799316406
Epoch: [0][10/69]	Time  0.25 ( 0.41)	Data  0.09 ( 0.17)	Loss   2.50 (  2.82)
2.603278636932373 0.14768362045288086
2.429023027420044 0.1425013542175293
2.401268482208252 0.13857698440551758
2.421210289001465 0.1684703826904297
2.3671071529388428 0.15459918975830078
2.2176196575164795 0.1649627685546875
2.3615329265594482 0.14726018905639648
2.179337978363037 0.1755833625793457
2.2781596183776855 0.2112109661102295
2.2818262577056885 0.2237074375152588
Epoch: [0][20/69]	Time  0.25 ( 0.33)	Data  0.09 ( 0.13)	Loss   2.51 (  2.68)
2.1813583374023438 0.19875264167785645
1.963279128074646 0.2387256622314453
2.107910394668579 0.20426058769226074
2.1468071937561035 0.22138118743896484
2.077824115753174 0.19494009017944336
2.0833137035369873 0.22281455993652344
1.9922236204147339 0.2026352882385254
1.978257656097412 0.20241141319274902
2.1352832317352295 0.17551827430725098
2.018321990966797 0.2528419494628906
Epoch: [0][30/69]	Time  0.25 ( 0.30)	Data  0.09 ( 0.12)	Loss   2.27 (  2.55)
2.0551557540893555 0.21894216537475586
1.7130212783813477 0.2776064872741699
1.82621169090271 0.25908803939819336
1.9874212741851807 0.2145848274230957
1.9488294124603271 0.24116063117980957
2.1486287117004395 0.24611115455627441
1.8978843688964844 0.2987093925476074
1.8364182710647583 0.2589111328125
2.0879814624786377 0.24024415016174316
1.9604437351226807 0.2376244068145752
Epoch: [0][40/69]	Time  0.25 ( 0.29)	Data  0.09 ( 0.11)	Loss   2.20 (  2.46)
1.884273648262024 0.2519650459289551
1.9095206260681152 0.29107022285461426
1.6712039709091187 0.3142819404602051
1.8059158325195312 0.2964911460876465
1.693303108215332 0.29427671432495117
1.735513687133789 0.256270170211792
1.6721608638763428 0.25347328186035156
1.7223949432373047 0.262113094329834
1.5510987043380737 0.33084988594055176
1.723740816116333 0.2554893493652344
Epoch: [0][50/69]	Time  0.25 ( 0.28)	Data  0.09 ( 0.11)	Loss   1.98 (  2.38)
1.6948094367980957 0.28539609909057617
1.7904605865478516 0.2502601146697998
1.6140137910842896 0.31090736389160156
1.6842842102050781 0.29561710357666016
1.4491221904754639 0.3081326484680176
1.6490907669067383 0.28902459144592285
1.754940152168274 0.2796659469604492
1.7638561725616455 0.29549646377563477
1.756590485572815 0.29413270950317383
1.6642929315567017 0.2830355167388916
Epoch: [0][60/69]	Time  0.25 ( 0.27)	Data  0.09 ( 0.11)	Loss   1.95 (  2.31)
1.7456388473510742 0.30182504653930664
1.60697340965271 0.3010571002960205
1.6143323183059692 0.33344101905822754
1.746396541595459 0.26142001152038574
1.4148935079574585 0.37120890617370605
1.4231876134872437 0.34473085403442383
1.6759073734283447 0.2946758270263672
1.7090847492218018 0.6494841575622559
Test: [ 0/69]	Time  0.976 ( 0.976)	Loss 2.7303e+00 (2.7303e+00)	Acc@1  29.69 ( 29.69)
Test: [10/69]	Time  0.093 ( 0.171)	Loss 1.2710e+00 (2.2243e+00)	Acc@1  70.31 ( 49.43)
Test: [20/69]	Time  0.082 ( 0.130)	Loss 6.3050e-01 (2.2889e+00)	Acc@1  81.25 ( 46.88)
Test: [30/69]	Time  0.085 ( 0.116)	Loss 1.5349e+00 (2.3911e+00)	Acc@1  62.50 ( 46.42)
Test: [40/69]	Time  0.084 ( 0.109)	Loss 2.2403e+00 (2.3443e+00)	Acc@1  59.38 ( 48.40)
Test: [50/69]	Time  0.098 ( 0.106)	Loss 1.4513e+00 (2.3702e+00)	Acc@1  68.75 ( 48.65)
Test: [60/69]	Time  0.084 ( 0.103)	Loss 2.8654e+00 (2.3743e+00)	Acc@1  31.25 ( 48.51)
 * Acc@1 47.675
lr: 0.006817316198804997
Traceback (most recent call last):
  File "/workspace/guoxingzhuo/Transfer-Learning-Library/examples/domain_adaptation/source_free_domain_adaptation/shot.py", line 356, in <module>
    main(args)
  File "/workspace/guoxingzhuo/Transfer-Learning-Library/examples/domain_adaptation/source_free_domain_adaptation/shot.py", line 128, in main
    train_target(train_loader, classifier, optimizer, lr_scheduler, epoch, args)
  File "/workspace/guoxingzhuo/Transfer-Learning-Library/examples/domain_adaptation/source_free_domain_adaptation/shot.py", line 245, in train_target
    pesudo_labels = collect_pseudo_labels(train_loader, model, args)
  File "/workspace/guoxingzhuo/Transfer-Learning-Library/examples/domain_adaptation/source_free_domain_adaptation/shot.py", line 168, in collect_pseudo_labels
    all_feature = torch.cat((all_feature, torch.ones(all_feature.size(0), 1)), 1)
KeyboardInterrupt
